{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üî∞Cet projet consiste √† pr√©dire si un client de Telecom va se d√©sabonner ou pas. Ceci est une notebook de recherche qui nous servira √† faire l'analyse exploratoire des donn√©es de l'entreprise afin de pouvoir cr√©er un mod√®le de machine learning capable de pr√©dire si un client se d√©sabonnera ou non.\n",
    "\n",
    "#### ‚öúüí¢Je me nomme Chrystal Orian VIGAN. Je suis datascientiste. Email: viganchrystal@gmail.com\n",
    "\n",
    "##### ‚è∏D√©but de projet: 18/03/2024\n",
    "\n",
    "### üìëSteps\n",
    " #####  1- Analyse exploratoire des donn√©es (EDA)\n",
    " #####  2- Pre-traitement des donnees (Preprocessing)\n",
    " #####  3- Cr√©ation des mod√®les de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des modules\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer \n",
    "from sklearn.metrics import RocCurveDisplay, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTATION DE NOTRE DATASET\n",
    "\n",
    "Data = pd.read_csv('./data/WA_Fn-UseC_-Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Data.copy()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape', df.shape)\n",
    "print('\\n')\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes.value_counts())\n",
    "print('\\n')\n",
    "print(df.dtypes.value_counts().plot.pie())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['customerID'].nunique() == df.shape[0]\n",
    "\n",
    "# #Nous constatons que la colonne 'customerID' est l'identifiant de chaque client au \n",
    "# niveau de l'entreprise. Alors elle ne nous apportera aucune information dans l'analyse \n",
    "# et la pr√©diction dans ce cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('customerID', axis=1)\n",
    "\n",
    "print(df.shape)\n",
    "print('\\n')\n",
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()\n",
    "\n",
    "# Nous constatons qu'il y a pas de valeur manquante dans notre dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "\n",
    "trainset, test = train_test_split(df, test_size=0.3, random_state=seed, stratify=df['Churn'])\n",
    "test, validate = train_test_split(test, test_size=0.5, random_state=seed, stratify=test['Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrement des Jeux de donn√©es\n",
    "\n",
    "trainset.to_csv('./data/train.csv', index=False)\n",
    "test.to_csv('./data/test.csv', index=False)\n",
    "validate.to_csv('./data/validate.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = trainset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = train.select_dtypes(include='object')\n",
    "numerical = train.select_dtypes(exclude='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical:\n",
    "    print(f'{col :-<50} {train[col].unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Nous constatons que la variable 'TotalCharges' est de types float mais la machine la consid√®re comme une varibles de types objet....\n",
    " Nous allons bien l'analyser et voir la raison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(df['TotalCharges'], errors='raise')\n",
    "#Ce code avec son argument errors=\"raise\" nous a permis de savoirs par exemple qu'√† la ligne 488, il y a aucune valeurs \"  \" . Ce qui traduit pourquoi la machine a consid√©rer\n",
    "# la variable 'TotalCharge' comme √©tant une variables de types objets car il y a beaucoup de donn√©es vide. Avec le m√™me code et sont arguments errors=\"coerce\", nous allons \n",
    "# convertir cette valeur manquante en NaN. Nous feront ceci dans l'√©tape de preprocessing.\n",
    "\n",
    "df['TotalCharges'][484:493]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagramme a barre de chaque variables quantitatives\n",
    "\n",
    "for col in numerical:\n",
    "    plt.figure()\n",
    "    sns.displot(train[col])\n",
    "    plt.legend(col)\n",
    "    plt.show()\n",
    "    plt.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical:\n",
    "    plt.figure()\n",
    "    sns.countplot(data=train, x=col)\n",
    "    plt.legend(col)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical:\n",
    "    plt.figure()\n",
    "    sns.heatmap(pd.crosstab(train['Churn'],\n",
    "                            train[col]), annot=True, fmt='d')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(numerical.corr(), annot=True, cmap=\"RdBu\", fmt='2g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(numerical.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical:\n",
    "    print(f'{col:-<50} {train[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical:\n",
    "    plt.figure()\n",
    "    train[col].value_counts().plot.pie()\n",
    "    plt.title(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Churn'].value_counts(normalize=True)\n",
    "\n",
    "# Nous constatons qu'il y a une forte d√©s√©quilibre de classe dans notre variable cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous allons traiter la variable TotalCharges\n",
    "\n",
    "def convert_total_charge(df, column_name):\n",
    "    '''\n",
    "    Cette nous permettra de convertir les lignes vides de la variable TotalCharges en NaN et donc la vonvertir en float\n",
    "\n",
    "    input:\n",
    "          df = dataset\n",
    "          column_name = 'TotalCharges'\n",
    "    output:\n",
    "          df modifie\n",
    "    '''\n",
    "    df[column_name] = df[column_name].replace(' ', np.nan).astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = convert_total_charge(train, 'TotalCharges')\n",
    "valide = convert_total_charge(validate, 'TotalCharges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_x_y(df):\n",
    "    y = df['Churn']\n",
    "    x = df.drop('Churn', axis=1)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#churn = df['Churn']\n",
    "numerical_df = train.select_dtypes(exclude='object')\n",
    "categorical_df = train.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pileline de preprocessing\n",
    "\n",
    "numerical_transformer = make_pipeline(('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                      ('standard', StandardScaler()))\n",
    "\n",
    "categorical_transformer = make_pipeline('encoder', OneHotEncoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = make_column_transformer((numerical_transformer, numerical_df),\n",
    "                                        (categorical_transformer, categorical_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest = make_pipeline(preprocessing, RandomForestClassifier(random_state=seed))\n",
    "\n",
    "KNN = make_pipeline(preprocessing, KNeighborsClassifier())\n",
    "\n",
    "SVM = make_pipeline(preprocessing, SVC(random_state=seed))\n",
    "\n",
    "ADA = make_pipeline(preprocessing, AdaBoostClassifier(random_state=seed))\n",
    "\n",
    "Log_regre = make_pipeline(preprocessing, LogisticRegression(random_state=seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_model = {'RandomForestClassifier' : RandomForest,\n",
    "              'KNeighborsClassifier': KNN,\n",
    "              'SVC': SVM,\n",
    "              'AdaBoostClassifier' : ADA,\n",
    "              'LogisticRegression' : Log_regre}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = cut_x_y(train)\n",
    "x_val, y_val = cut_x_y(valide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_val_pred = model.predict(x_val)\n",
    "\n",
    "    print(confusion_matrix(y_val, y_val_pred))\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "    N, train_score, val_score = learning_curve(model , x_train, y_train, cv=4,\n",
    "                                               scoring='f1_score', train_sizes=np.linspace(0.1, 1, 10))\n",
    "    \n",
    "    rf_roc = RocCurveDisplay.from_estimator(model, x_val, y_val)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    print(rf_roc)\n",
    "    plt.plot(N, train_score.mean(axis=1), label='train score')\n",
    "    plt.plot(N, val_score.mean(axis=1), label='validation score')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in dict_model.items():\n",
    "    print(name)\n",
    "    evaluation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hollo x')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
